{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade Tools: extracting and cleaning Japanese trade data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tradefile import TradeFile\n",
    "from customsgrabber import CustomsGrabber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping trade data from the customs: the CustomsGrabber object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of 2021, unfortunately, while the Japanese trade data are open to consult, the official website of the Japanese Customs does not provide a dynamic connection to the trade data at the row level, and it is not possible to query the database in order to extract data for specific conditions (e.g. country and commodity). Instead, the website provides either a closed query interface or a set of files divided by month and by a subset of the commodity codes, either the Principal Commodity codes or the HS (Harmonized System) codes.\n",
    "\n",
    "The class CustomsGrabber provides a downloader for the trade data from the Japanese Customs Website. The data are saved as a zip containing one or more csv file. The single csv files are original from the website.\n",
    "Currently, CustomsGrabber is able to download one or more years of data along these two dimensions:\n",
    "- *direction*: 'import' (goods to Japan) or 'export';\n",
    "The *kind*, 'HS' (the international Harmonized System coding) or 'PC' (Principal Commodity, a summarization of HS codes by categories that the Japanese Government deems useful) is inferred by the columns of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/public/Documents/coding/git_repo/JapanTrade/src/japantrade/customsgrabber.py:117: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 117 of the file /mnt/c/Users/public/Documents/coding/git_repo/JapanTrade/src/japantrade/customsgrabber.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  year_html = BeautifulSoup(year_page)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the data as import_HS_2021-2021.zip in ../data/.\n"
     ]
    }
   ],
   "source": [
    "grabber = CustomsGrabber()\n",
    "grabber.grabRange(from_year=2021, to_year=2021, direction='import', kind='HS') # data from 2019 only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming raw tables into workable data: the TradeFile object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class TradeFile provides the tools to open and transform a wide form csv file from the Japanese Customs website.\n",
    "The files are in wide format, with month columns possibly multiplied by the number of units (e.g. Kgs, Number of units, and thousands JPY).\n",
    "\n",
    "TradeFile can open a single csv file, or more files from a zip archive, merge and normalize the data so that the resulting DataFrame will have the following form:\n",
    "- The commodity code\n",
    "- The target country\n",
    "- The date (month and year) of acquisition\n",
    "- The unit of measure\n",
    "- The value or the measure\n",
    "\n",
    "TradeFile can also open text data that have already been normalized. The flag _raw_ is used to indicate whether we are opening a \"raw\" file or a normalized one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tradefile   : WARNING  Warning: this operation might take more than one  minute if the file spans over more years.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening ../data/import_HS_2021-2021.zip...\n",
      "Loading the file...\n",
      "Unpivoting the monthly columns. This might take a minute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tradefile   : INFO     The melting took 0.4032611846923828, the splitting 3.2825939655303955, the cleaning 0.798795223236084 and the date merging time is 2.037729024887085.\n",
      "tradefile   : INFO     Unpivoting the metrics...\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/import_HS_2021-2021.zip\"\n",
    "tool = TradeFile(path, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging new data to an existing (text) database\n",
    "\n",
    "For periodic (say, monthly) updates of the database, it is possible to specify an existing textfile or a DataFrame containing an already normalized trade table. The parameters to use are:\n",
    "- _merge_file_: in case of a starting csv file\n",
    "- _merge_df_: in case the DataFrame is already in memory.\n",
    "\n",
    "Note that it is assumed that the base DataFrame is already normalized. While merging two raw files is currently not supported with this method, note that it is always possible to open a zip archive with two or more raw files in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = \"../data/import_HS_2021-2021.zip\"\n",
    "merged_df = TradeFile(path2, raw=True, merge_file=\"../data/import_HS_2016-01_2021-04.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the normalized data\n",
    "\n",
    "Once acquired, the trade DataFrame can be accessed under _.data_. This is a common Pandas DataFrame and can be manipulated as such. Note that currently _.data_ is not protected, so be careful to respect its original data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50215654.07262021"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_july_07 = (tool.data['date'] == \"2021-07-01\")\n",
    "is_jpy = (tool.data['unit'] == 'JPY')\n",
    "is_italy = (tool.data['country'] == '220')\n",
    "tool.data[is_july_07 & is_jpy & is_italy]['value'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data to file\n",
    "\n",
    "The trade dataframe can be saved to csv or zip file through the method _save_to_file_. The method will generate a file with name _[kind]__[first date]__[last_date].csv_. In case _is_zip_ is set to True, the extension will be _.zip_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tradefile   : INFO     TradeFile.save_to_file: saved data to ../data/HS_2016-01-01_2021-07-01.csv.\n"
     ]
    }
   ],
   "source": [
    "tool.save_to_file(path=\"../data\", is_zip=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
